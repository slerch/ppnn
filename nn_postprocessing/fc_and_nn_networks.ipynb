{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Fully-connected-linear-network\" data-toc-modified-id=\"Fully-connected-linear-network-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Fully connected linear network</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Get-temperature-data\" data-toc-modified-id=\"Get-temperature-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Get temperature data</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Build-fully-connected-model\" data-toc-modified-id=\"Build-fully-connected-model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Build fully connected model</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Predict-for-one-day\" data-toc-modified-id=\"Predict-for-one-day-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Predict for one day</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Post-processing-with-rolling-window-for-2016\" data-toc-modified-id=\"Post-processing-with-rolling-window-for-2016-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Post processing with rolling window for 2016</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Train-2015,-predict-2016\" data-toc-modified-id=\"Train-2015,-predict-2016-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Train 2015, predict 2016</a></span></li></ul></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Neural-network-with-one-hidden-layer\" data-toc-modified-id=\"Neural-network-with-one-hidden-layer-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Neural network with one hidden layer</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Build-network\" data-toc-modified-id=\"Build-network-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Build network</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Train-2015,-predict-2016\" data-toc-modified-id=\"Train-2015,-predict-2016-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Train 2015, predict 2016</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Making-the-hidden-model-more-complex\" data-toc-modified-id=\"Making-the-hidden-model-more-complex-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Making the hidden model more complex</a></span></li></ul></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Add-station-embeddings\" data-toc-modified-id=\"Add-station-embeddings-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Add station embeddings</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Build-linear-embedding-model\" data-toc-modified-id=\"Build-linear-embedding-model-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Build linear embedding model</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Train-2015,-predict-2016\" data-toc-modified-id=\"Train-2015,-predict-2016-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Train 2015, predict 2016</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Embedding-size-hyper-parameter-tuning\" data-toc-modified-id=\"Embedding-size-hyper-parameter-tuning-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Embedding size hyper-parameter tuning</a></span></li></ul></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Adding-auxiliary-variables\" data-toc-modified-id=\"Adding-auxiliary-variables-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Adding auxiliary variables</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Load-extended-dataset\" data-toc-modified-id=\"Load-extended-dataset-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Load extended dataset</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Linear-model\" data-toc-modified-id=\"Linear-model-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Linear model</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Hidden-model\" data-toc-modified-id=\"Hidden-model-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Hidden model</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Even-more-variables\" data-toc-modified-id=\"Even-more-variables-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Even more variables</a></span></li></ul></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Additional-variables-with-the-embedding-model\" data-toc-modified-id=\"Additional-variables-with-the-embedding-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Additional variables with the embedding model</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Linear-model-with-embeddings\" data-toc-modified-id=\"Linear-model-with-embeddings-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Linear model with embeddings</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#Hidden-model-with-embeddings\" data-toc-modified-id=\"Hidden-model-with-embeddings-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Hidden model with embeddings</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#A-longer-training-period\" data-toc-modified-id=\"A-longer-training-period-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>A longer training period</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/fc_and_nn_networks.ipynb#A-longer-training-period-with-more-data\" data-toc-modified-id=\"A-longer-training-period-with-more-data-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>A longer training period with more data</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected and neural networks\n",
    "\n",
    "In this notebook we will expand the simple EMOS linear network to fully connected non-linear neural nets. Furthermore, we will also use auxiliary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anaconda environment: cbrain_gpu\n",
      "Linux 4.4.0-97-generic\n",
      "Anaconda environment: cbrain_gpu\n",
      "Linux 4.4.0-97-generic\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from importlib import reload\n",
    "import emos_network_theano; reload(emos_network_theano)\n",
    "from  emos_network_theano import EMOS_Network\n",
    "from losses import crps_cost_function\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "import keras_models; reload(keras_models)\n",
    "from keras_models import *\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic setup\n",
    "# DATA_DIR = '/Volumes/STICK/data/ppnn_data/'  # Mac\n",
    "DATA_DIR = '/project/meteo/w2w/C7/ppnn_data/'   # LMU\n",
    "results_dir = '../results/'\n",
    "window_size = 25   # Days in rolling window\n",
    "fclt = 48   # Forecast lead time in hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected linear network\n",
    "\n",
    "As a first step, we can build a linear model which also connects the means and standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get temperature data\n",
    "\n",
    "This follows the steps in the EMOS Network data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 25 days\n",
      "test set contains 1 days\n"
     ]
    }
   ],
   "source": [
    "date_str = '2011-02-14'\n",
    "train_set, test_set = get_train_test_sets(DATA_DIR, predict_date=date_str,\n",
    "                                          fclt=fclt, window_size=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Build fully connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fc_model = build_fc_model(2, 2, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we have 6 parameters instead of 4 with the standard EMOS Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Predict for one day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define some parameters\n",
    "early_stopping_delta = 1e-4   # How much the CRPS must improve before stopping\n",
    "steps_max = 1000   # How many steps to fit at max\n",
    "batch_size = train_set.features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fc_model.fit(train_set.features, train_set.targets, epochs=steps_max, \n",
    "             batch_size=batch_size,\n",
    "             validation_data=[test_set.features, test_set.targets], \n",
    "             verbose=0,\n",
    "             callbacks=[EarlyStopping(monitor='loss', \n",
    "                                      min_delta=early_stopping_delta,\n",
    "                                      patience=2)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1270655771548999, 0.76711642082605846)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get train and test CRPS\n",
    "(fc_model.evaluate(train_set.features, train_set.targets, batch_size, verbose=0), \n",
    " fc_model.evaluate(test_set.features, test_set.targets, batch_size, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For this particular day we get a score that is slightly better than the standard EMOS network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Post processing with rolling window for 2016\n",
    "\n",
    "As with the EMOS models let's do a rolling window global post-processing for 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "date_str_start = '2016-01-01'\n",
    "date_str_stop = '2017-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fc_model = build_fc_model(2, 2, compile=True, optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/366 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 366/366 [08:33<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use the loop function in utils\n",
    "train_crps_list, valid_crps_list, results_df = loop_over_days(\n",
    "    DATA_DIR,\n",
    "    fc_model,\n",
    "    date_str_start, date_str_stop, \n",
    "    window_size=window_size,\n",
    "    fclt=fclt,     \n",
    "    epochs_max=steps_max, \n",
    "    early_stopping_delta=early_stopping_delta, \n",
    "    lr=0.1,   \n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98830469069443005, 1.0057136710506112)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_crps_list), np.mean(valid_crps_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So we get a slightly better training score and a slightly worse test score. This is a sign of overfitting. But the differences are small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results_df.to_csv(results_dir + 'fc_network_rolling_window.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train 2015, predict 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 365 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "train_dates = ['2015-01-01', '2016-01-01']\n",
    "test_dates =  ['2016-01-01', '2017-01-01']\n",
    "train_set, test_set = get_train_test_sets(DATA_DIR, train_dates, test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fc_model = build_fc_model(2, 2, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fc_model.compile(keras.optimizers.Adam(0.001), loss=crps_cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0702 - val_loss: 1.0127\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0700 - val_loss: 1.0127\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0698 - val_loss: 1.0124ss: 1.\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0697 - val_loss: 1.0125\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0696 - val_loss: 1.0123\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0695 - val_loss: 1.0122\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0694 - val_loss: 1.0123\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0694 - val_loss: 1.0122\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0693 - val_loss: 1.0122\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0693 - val_loss: 1.0122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122b17198>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: I am running this cell several times (40)\n",
    "fc_model.fit(train_set.features, train_set.targets, epochs=10, batch_size=1024,\n",
    "             validation_data=[test_set.features, test_set.targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Very similar to the standard EMOS Network. This indicates that there is not much additional information in the two extra connections we added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = fc_model.predict(test_set.features)\n",
    "results_df = create_results_df(test_set.date_strs, test_set.station_ids,\n",
    "                               preds[:, 0], preds[:, 1])\n",
    "results_df.to_csv(results_dir + 'fc_network_train_2015_pred_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Neural network with one hidden layer\n",
    "\n",
    "Now we will build the first neural network with a hidden layer and a non-linear activation function. We will restrict ourselves to testing the 2015 training, 2016 prediction case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hidden_model = build_hidden_model(2, 2, hidden_nodes=10, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 52\n",
      "Trainable params: 52\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Train 2015, predict 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hidden_model.compile(keras.optimizers.Adam(0.0001), loss=crps_cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 4.1429 - val_loss: 1.4222\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.1146 - val_loss: 1.0142\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0724 - val_loss: 1.0159\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0716 - val_loss: 1.0158\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0718 - val_loss: 1.0135\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0715 - val_loss: 1.0147\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0714 - val_loss: 1.0136\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0710 - val_loss: 1.0144\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0710 - val_loss: 1.0139\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0712 - val_loss: 1.0161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1157c4470>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the same data from above!\n",
    "# Note I am running this cell several times\n",
    "hidden_model.fit(train_set.features, train_set.targets, epochs=10, batch_size=1024,\n",
    "                 validation_data=[test_set.features, test_set.targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Again, the results are pretty similar. This indicates that for the given data, the added nonlinearity is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = hidden_model.predict(test_set.features)\n",
    "results_df = create_results_df(test_set.date_strs, test_set.station_ids,\n",
    "                               preds[:, 0], preds[:, 1])\n",
    "results_df.to_csv(results_dir + 'hidden_nn_train_2015_pred_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Making the hidden model more complex\n",
    "\n",
    "Let's see what happens if we make the model more complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hidden_model = build_hidden_model(2, 2, hidden_nodes=[100, 100, 100], compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 20,702\n",
      "Trainable params: 20,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hidden_model.compile(keras.optimizers.Adam(0.0001), loss=crps_cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 2s - loss: 1.0570 - val_loss: 1.0217\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 2s - loss: 1.0570 - val_loss: 1.0224\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 2s - loss: 1.0570 - val_loss: 1.0221\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 2s - loss: 1.0571 - val_loss: 1.0223\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 2s - loss: 1.0570 - val_loss: 1.0221\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 2s - loss: 1.0570 - val_loss: 1.0221\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 2s - loss: 1.0570 - val_loss: 1.0223\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 2s - loss: 1.0570 - val_loss: 1.0223\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 2s - loss: 1.0569 - val_loss: 1.0219\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 2s - loss: 1.0569 - val_loss: 1.0221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118c75860>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_model.fit(train_set.features, train_set.targets, epochs=10, batch_size=4096,\n",
    "                 validation_data=[test_set.features, test_set.targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So we can see that even for a model with 20,000 parameters then training score only goes down a few percent. For a simple bias and spread correction, a linear model seems fully sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add station embeddings\n",
    "\n",
    "Next we will add a station embedding. Here we are giving every station additional parameters which the model can learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Build linear embedding model\n",
    "\n",
    "Let's build a linear embedding model. I tried out hidden layers, but they seem to make the validation score worse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = 3\n",
    "max_id = int(np.max([train_set.cont_ids.max(), test_set.cont_ids.max()]))\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_model = build_emb_model(2, 2, [], emb_size, max_id, compile=True,\n",
    "                            lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_21 (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)          (None, 1, 3)          1611        input_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_20 (InputLayer)            (None, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 3)             0           embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 5)             0           input_20[0][0]                   \n",
      "                                                                   flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 2)             12          concatenate_6[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 1,623\n",
      "Trainable params: 1,623\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Train 2015, predict 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9690 - val_loss: 0.9132\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9691 - val_loss: 0.9129\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9690 - val_loss: 0.9129\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9690 - val_loss: 0.9136\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9691 - val_loss: 0.9132\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9689 - val_loss: 0.9139\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9689 - val_loss: 0.9131\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9690 - val_loss: 0.9138\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9689 - val_loss: 0.9128\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9690 - val_loss: 0.9134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b9b5c50>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ran this for 40 epochs\n",
    "emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, \n",
    "              epochs=10, batch_size=1024, \n",
    "              validation_data=[[test_set.features, test_set.cont_ids], test_set.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = emb_model.predict([test_set.features, test_set.cont_ids])\n",
    "results_df = create_results_df(test_set.date_strs, test_set.station_ids,\n",
    "                               preds[:, 0], preds[:, 1])\n",
    "results_df.to_csv(results_dir + 'embedding_fc_train_2015_pred_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Embedding size hyper-parameter tuning\n",
    "\n",
    "Since embeddings appear to work very well, we will test the impact of the embedding size before building more complex models. Of course, a larger embedding size might be useful when adding more variables, but this should give us some feeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_and_run_emb_model(emb_size):\n",
    "    emb_model = build_emb_model(2, 2, [], emb_size, max_id, compile=True)\n",
    "    emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, \n",
    "                  epochs=40,batch_size=1024, verbose=0,\n",
    "                  validation_data=[[test_set.features, test_set.cont_ids], test_set.targets])\n",
    "    print(emb_model.evaluate([train_set.features, train_set.cont_ids], train_set.targets, verbose=0),\n",
    "          emb_model.evaluate([test_set.features, test_set.cont_ids], test_set.targets, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.975157575805 0.918841918992\n",
      "2\n",
      "0.96694133538 0.913661904937\n",
      "3\n",
      "0.967165116694 0.912928815584\n",
      "5\n",
      "0.967104299998 0.914134442874\n",
      "10\n",
      "0.968233569106 0.915652121524\n",
      "20\n",
      "0.969342381379 0.912989628939\n"
     ]
    }
   ],
   "source": [
    "for emb_size in [1, 2, 3, 5, 10, 20]:\n",
    "    print(emb_size)\n",
    "    build_and_run_emb_model(emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that there is some variability. In our first experiment above with an embedding size of 5 we got a better score than here. For this very simple network an embedding size of three seems sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding auxiliary variables\n",
    "\n",
    "Now we can try adding additional variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load extended dataset\n",
    "\n",
    "Using the function defined in utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The prepare_data function takes an ordered dict as an input\n",
    "aux_dict = OrderedDict()\n",
    "aux_dict['data_aux_geo_interpolated.nc'] = ['orog', \n",
    "                                            'station_alt', \n",
    "                                            'station_lat', \n",
    "                                            'station_lon']\n",
    "aux_dict['data_aux_pl500_interpolated_00UTC.nc'] = ['u_pl500_fc',\n",
    "                                                    'v_pl500_fc',\n",
    "                                                    'gh_pl500_fc']\n",
    "aux_dict['data_aux_pl850_interpolated_00UTC.nc'] = ['u_pl850_fc',\n",
    "                                                    'v_pl850_fc',\n",
    "                                                    'q_pl850_fc']\n",
    "aux_dict['data_aux_surface_interpolated_00UTC.nc'] = ['cape_fc',\n",
    "                                                      'sp_fc',\n",
    "                                                      'tcc_fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 365 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "train_dates = ['2015-01-01', '2016-01-01']\n",
    "test_dates =  ['2016-01-01', '2017-01-01']\n",
    "train_set, test_set = get_train_test_sets(DATA_DIR, train_dates, test_dates,\n",
    "                                         aux_dict=aux_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180849, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = build_fc_model(train_set.features.shape[1], 2, compile=True, \n",
    "                          lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9701 - val_loss: 0.9389\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9699 - val_loss: 0.9395\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9699 - val_loss: 0.9405\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9700 - val_loss: 0.9385\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9702 - val_loss: 0.9380\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9699 - val_loss: 0.9385\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9699 - val_loss: 0.9384\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9699 - val_loss: 0.9400\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9698 - val_loss: 0.9388\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9699 - val_loss: 0.9382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c21d5c0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that I am running this cell multiple times\n",
    "fc_model.fit(train_set.features, train_set.targets, epochs=10, batch_size=1024,\n",
    "             validation_data=[test_set.features, test_set.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = fc_model.predict([test_set.features, test_set.cont_ids])\n",
    "results_df = create_results_df(test_set.date_strs, test_set.station_ids,\n",
    "                               preds[:, 0], preds[:, 1])\n",
    "results_df.to_csv(results_dir + 'embedding_fc_train_2015_pred_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_model = build_hidden_model(train_set.features.shape[1], 2, \n",
    "                                  hidden_nodes=[50], compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_49 (InputLayer)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 50)                1250      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 1,352\n",
      "Trainable params: 1,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9388 - val_loss: 0.9402\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9348 - val_loss: 0.9332\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9346 - val_loss: 0.9367\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9295 - val_loss: 0.9418\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9292 - val_loss: 0.9356\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9275 - val_loss: 0.9392\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9253 - val_loss: 0.9365\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9251 - val_loss: 0.9378\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9239 - val_loss: 0.9441\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9232 - val_loss: 0.9310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1264243c8>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that I am running this cell multiple times\n",
    "hidden_model.fit(train_set.features, train_set.targets, epochs=10, batch_size=1024,\n",
    "             validation_data=[test_set.features, test_set.targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see a definite improvement using auxiliary variables. Again, the hidden layer does not seem to improve things a lot compared to the simple linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even more variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_aux_dict = aux_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_aux_dict['data_aux_surface_more_interpolated_part1_00UTC.nc']  = [\n",
    "    'sshf_fc', 'slhf_fc', 'u10_fc','v10_fc'\n",
    "]\n",
    "more_aux_dict['data_aux_surface_more_interpolated_part2_00UTC.nc']  = [\n",
    "    'ssr_fc', 'str_fc', 'd2m_fc','sm_fc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 365 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "more_train_set, more_test_set = get_train_test_sets(DATA_DIR, train_dates, test_dates,\n",
    "                                         aux_dict=more_aux_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180849, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_train_set.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = build_fc_model(more_train_set.features.shape[1], 2, compile=True, \n",
    "                          lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9540 - val_loss: 0.9163\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9542 - val_loss: 0.9231\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9546 - val_loss: 0.9159\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9546 - val_loss: 0.9242\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9544 - val_loss: 0.9152\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9549 - val_loss: 0.9251\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9545 - val_loss: 0.9161\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9542 - val_loss: 0.9193\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9545 - val_loss: 0.9177\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9539 - val_loss: 0.9221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2aed4cd4e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that I am running this cell multiple times\n",
    "fc_model.fit(more_train_set.features, more_train_set.targets, epochs=10, batch_size=1024,\n",
    "             validation_data=[more_test_set.features, more_test_set.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding these extra variables gets us another percent or so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional variables with the embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Linear model with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_model = build_emb_model(train_set.features.shape[1], 2, [], 3, max_id, \n",
    "                            compile=True, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 1, 3)          1611        input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_1 (InputLayer)             (None, 24)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 3)             0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 27)            0           input_1[0][0]                    \n",
      "                                                                   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2)             56          concatenate_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 1,667\n",
      "Trainable params: 1,667\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9234 - val_loss: 0.9007\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9232 - val_loss: 0.8995\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9233 - val_loss: 0.8985\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9231 - val_loss: 0.9004\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9231 - val_loss: 0.8981\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9230 - val_loss: 0.8987\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9232 - val_loss: 0.8977\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9231 - val_loss: 0.8979\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9229 - val_loss: 0.8969\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9231 - val_loss: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96c40f5dd8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again I am running this multiple times\n",
    "emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, epochs=10, \n",
    "              batch_size=1024, \n",
    "              validation_data=[[test_set.features, test_set.cont_ids], test_set.targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden model with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model = build_emb_model(train_set.features.shape[1], 2, [50], 3, max_id, \n",
    "                            compile=True, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8592 - val_loss: 0.8559\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8536 - val_loss: 0.8559\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8524 - val_loss: 0.8590\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8498 - val_loss: 0.8570\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8500 - val_loss: 0.8580\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8478 - val_loss: 0.8885\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8465 - val_loss: 0.8572\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8449 - val_loss: 0.8564\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8438 - val_loss: 0.8583\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8440 - val_loss: 0.8613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f95e113fcc0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again I am running this multiple times\n",
    "emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, epochs=10, \n",
    "              batch_size=4096, \n",
    "              validation_data=[[test_set.features, test_set.cont_ids], test_set.targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our best score so far. Here the non-linearity seems to make a difference compared to the simple linear model. But we do get some overfitting. Let's try out some techniques. Fewer or more hidden nodes does not seem to change all that much.\n",
    "\n",
    "No we need to be very careful here. I am currently stopping when the validation score does not decrease further. THIS IS CHEATING!\n",
    "\n",
    "Let's try doing the train valid split just with the training set, and see if we can get a good early stopping point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_id = int(np.max([train_set.cont_ids.max(), test_set.cont_ids.max()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = build_emb_model(train_set.features.shape[1], 2, [50], 3, max_id, \n",
    "                            compile=True, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144679 samples, validate on 36170 samples\n",
      "Epoch 1/50\n",
      "144679/144679 [==============================] - 0s - loss: 4.6977 - val_loss: 2.3896\n",
      "Epoch 2/50\n",
      "144679/144679 [==============================] - 0s - loss: 2.5777 - val_loss: 1.8083\n",
      "Epoch 3/50\n",
      "144679/144679 [==============================] - 0s - loss: 1.3762 - val_loss: 1.1476\n",
      "Epoch 4/50\n",
      "144679/144679 [==============================] - 0s - loss: 1.0260 - val_loss: 1.0796\n",
      "Epoch 5/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.9704 - val_loss: 1.0552\n",
      "Epoch 6/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.9508 - val_loss: 1.0323\n",
      "Epoch 7/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.9369 - val_loss: 1.0165\n",
      "Epoch 8/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.9260 - val_loss: 1.0029\n",
      "Epoch 9/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.9199 - val_loss: 0.9962\n",
      "Epoch 10/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.9133 - val_loss: 0.9905\n",
      "Epoch 11/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.9092 - val_loss: 0.9868\n",
      "Epoch 12/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.9064 - val_loss: 0.9832\n",
      "Epoch 13/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.9035 - val_loss: 0.9789\n",
      "Epoch 14/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.9005 - val_loss: 0.9757\n",
      "Epoch 15/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.8962 - val_loss: 0.9704\n",
      "Epoch 16/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.8904 - val_loss: 0.9731\n",
      "Epoch 17/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.8828 - val_loss: 0.9568\n",
      "Epoch 18/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.8703 - val_loss: 0.9546\n",
      "Epoch 19/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.8659 - val_loss: 0.9551\n",
      "Epoch 20/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.8602 - val_loss: 0.9513\n",
      "Epoch 21/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.8587 - val_loss: 0.9509\n",
      "Epoch 22/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.8563 - val_loss: 0.9473\n",
      "Epoch 23/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.8528 - val_loss: 0.9582\n",
      "Epoch 24/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.8512 - val_loss: 0.9488\n",
      "Epoch 25/50\n",
      "144679/144679 [==============================] - 0s - loss: 0.8479 - val_loss: 0.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a3c190208>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again I am running this multiple times\n",
    "emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, epochs=50, \n",
    "              batch_size=4096, validation_split=0.2,\n",
    "              callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                       min_delta=0,\n",
    "                                       patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000/182218 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8661767004406562"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate([test_set.features, test_set.cont_ids], test_set.targets, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = emb_model.predict([test_set.features, test_set.cont_ids])\n",
    "results_df = create_results_df(test_set.date_strs, test_set.station_ids,\n",
    "                               preds[:, 0], preds[:, 1])\n",
    "results_df.to_csv(results_dir + 'embedding_nn_aux_train_2015_pred_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A longer training period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 2922 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "long_train_dates = ['2008-01-01', '2016-01-01']\n",
    "test_dates =  ['2016-01-01', '2017-01-01']\n",
    "long_train_set, test_set = get_train_test_sets(DATA_DIR, long_train_dates, test_dates,\n",
    "                                               aux_dict=aux_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model = build_emb_model(long_train_set.features.shape[1], 2, [50], 3, max_id, \n",
    "                            compile=True, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1165581 samples, validate on 291396 samples\n",
      "Epoch 1/50\n",
      "1165581/1165581 [==============================] - 2s - loss: 1.4502 - val_loss: 0.9145\n",
      "Epoch 2/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.9202 - val_loss: 0.8564\n",
      "Epoch 3/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8807 - val_loss: 0.8377\n",
      "Epoch 4/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8701 - val_loss: 0.8407\n",
      "Epoch 5/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8637 - val_loss: 0.8339\n",
      "Epoch 6/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8568 - val_loss: 0.8292\n",
      "Epoch 7/50\n",
      "1165581/1165581 [==============================] - 2s - loss: 0.8490 - val_loss: 0.8261\n",
      "Epoch 8/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8440 - val_loss: 0.8225\n",
      "Epoch 9/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8399 - val_loss: 0.8217\n",
      "Epoch 10/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8383 - val_loss: 0.8156\n",
      "Epoch 11/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8364 - val_loss: 0.8159\n",
      "Epoch 12/50\n",
      "1165581/1165581 [==============================] - 2s - loss: 0.8346 - val_loss: 0.8159\n",
      "Epoch 13/50\n",
      "1165581/1165581 [==============================] - 2s - loss: 0.8327 - val_loss: 0.8124\n",
      "Epoch 14/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8311 - val_loss: 0.8180\n",
      "Epoch 15/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8304 - val_loss: 0.8205\n",
      "Epoch 16/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8298 - val_loss: 0.8160\n",
      "Epoch 17/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8260 - val_loss: 0.8331\n",
      "Epoch 18/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8263 - val_loss: 0.8065\n",
      "Epoch 19/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8244 - val_loss: 0.8076\n",
      "Epoch 20/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8231 - val_loss: 0.8086\n",
      "Epoch 21/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8222 - val_loss: 0.8100\n",
      "Epoch 22/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8205 - val_loss: 0.8088\n",
      "Epoch 23/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8212 - val_loss: 0.8046\n",
      "Epoch 24/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8183 - val_loss: 0.8043\n",
      "Epoch 25/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8190 - val_loss: 0.8064\n",
      "Epoch 26/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8188 - val_loss: 0.8047\n",
      "Epoch 27/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8181 - val_loss: 0.8219\n",
      "Epoch 28/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8192 - val_loss: 0.8082\n",
      "Epoch 29/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8155 - val_loss: 0.8045\n",
      "Epoch 30/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8163 - val_loss: 0.8183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2aec0a6e80>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again I am running this multiple times\n",
    "emb_model.fit([long_train_set.features, long_train_set.cont_ids], long_train_set.targets, \n",
    "              epochs=50, \n",
    "              batch_size=4096, validation_split=0.2,\n",
    "              callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                       min_delta=0,\n",
    "                                       patience=5)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000/182218 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7918927852063512"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate([test_set.features, test_set.cont_ids], test_set.targets, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = emb_model.predict([test_set.features, test_set.cont_ids])\n",
    "results_df = create_results_df(test_set.date_strs, test_set.station_ids,\n",
    "                               preds[:, 0], preds[:, 1])\n",
    "results_df.to_csv(results_dir + 'embedding_nn_aux_train_2008-2015_pred_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### A longer training period with more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 2922 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "long_more_train_set, more_test_set = get_train_test_sets(DATA_DIR, long_train_dates, test_dates,\n",
    "                                                         aux_dict=more_aux_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model = build_emb_model(long_more_train_set.features.shape[1], 2, [100], 3, max_id, \n",
    "                            compile=True, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1165581 samples, validate on 291396 samples\n",
      "Epoch 1/50\n",
      "1165581/1165581 [==============================] - 2s - loss: 1.4866 - val_loss: 0.8848\n",
      "Epoch 2/50\n",
      "1165581/1165581 [==============================] - 2s - loss: 0.8875 - val_loss: 0.8467\n",
      "Epoch 3/50\n",
      "1165581/1165581 [==============================] - 2s - loss: 0.8628 - val_loss: 0.8289\n",
      "Epoch 4/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8504 - val_loss: 0.8384\n",
      "Epoch 5/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8424 - val_loss: 0.8217\n",
      "Epoch 6/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8376 - val_loss: 0.8203\n",
      "Epoch 7/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8350 - val_loss: 0.8143\n",
      "Epoch 8/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8291 - val_loss: 0.8176\n",
      "Epoch 9/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8281 - val_loss: 0.8141\n",
      "Epoch 10/50\n",
      "1165581/1165581 [==============================] - 2s - loss: 0.8230 - val_loss: 0.8210\n",
      "Epoch 11/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8231 - val_loss: 0.8084\n",
      "Epoch 12/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8197 - val_loss: 0.8085\n",
      "Epoch 13/50\n",
      "1165581/1165581 [==============================] - 2s - loss: 0.8180 - val_loss: 0.8060\n",
      "Epoch 14/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8159 - val_loss: 0.8058\n",
      "Epoch 15/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8142 - val_loss: 0.8040\n",
      "Epoch 16/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8126 - val_loss: 0.8046\n",
      "Epoch 17/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8129 - val_loss: 0.8077\n",
      "Epoch 18/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8111 - val_loss: 0.8039\n",
      "Epoch 19/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8098 - val_loss: 0.8117\n",
      "Epoch 20/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8095 - val_loss: 0.8014\n",
      "Epoch 21/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8072 - val_loss: 0.8012\n",
      "Epoch 22/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8065 - val_loss: 0.8067\n",
      "Epoch 23/50\n",
      "1165581/1165581 [==============================] - 2s - loss: 0.8069 - val_loss: 0.8171\n",
      "Epoch 24/50\n",
      "1165581/1165581 [==============================] - 2s - loss: 0.8058 - val_loss: 0.8054\n",
      "Epoch 25/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8057 - val_loss: 0.8020\n",
      "Epoch 26/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8039 - val_loss: 0.8081\n",
      "Epoch 27/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8043 - val_loss: 0.8003\n",
      "Epoch 28/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8036 - val_loss: 0.8063\n",
      "Epoch 29/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8041 - val_loss: 0.8029\n",
      "Epoch 30/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8022 - val_loss: 0.8013\n",
      "Epoch 31/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8023 - val_loss: 0.8076\n",
      "Epoch 32/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8029 - val_loss: 0.8074\n",
      "Epoch 33/50\n",
      "1165581/1165581 [==============================] - 1s - loss: 0.8003 - val_loss: 0.8085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2aeb8e6f98>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again I am running this multiple times\n",
    "emb_model.fit([long_more_train_set.features, long_more_train_set.cont_ids], \n",
    "              long_more_train_set.targets, \n",
    "              epochs=50, batch_size=4096, validation_split=0.2,\n",
    "              callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                       min_delta=0,\n",
    "                                       patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000/182218 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79416574978415233"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate([more_test_set.features, more_test_set.cont_ids], more_test_set.targets, \n",
    "                   batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = emb_model.predict([more_test_set.features, more_test_set.cont_ids])\n",
    "results_df = create_results_df(test_set.date_strs, test_set.station_ids,\n",
    "                               preds[:, 0], preds[:, 1])\n",
    "results_df.to_csv(results_dir + 'embedding_nn_more_aux_train_2008-2015_pred_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
