{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#Set-up-data\" data-toc-modified-id=\"Set-up-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Set up data</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#RNNs-with-only-temperature-data\" data-toc-modified-id=\"RNNs-with-only-temperature-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>RNNs with only temperature data</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#RNN-predicting-only-the-last-target\" data-toc-modified-id=\"RNN-predicting-only-the-last-target-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>RNN predicting only the last target</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#Sequence-RNN\" data-toc-modified-id=\"Sequence-RNN-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Sequence RNN</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#Longer-sequence\" data-toc-modified-id=\"Longer-sequence-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Longer sequence</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#Add-dropout\" data-toc-modified-id=\"Add-dropout-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Add dropout</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#Reference-experiment-with-longer-training-set.\" data-toc-modified-id=\"Reference-experiment-with-longer-training-set.-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Reference experiment with longer training set.</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#Sequence-model-with-longer-training-set\" data-toc-modified-id=\"Sequence-model-with-longer-training-set-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Sequence model with longer training set</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#Get-additional-variables\" data-toc-modified-id=\"Get-additional-variables-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Get additional variables</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#Combining-with-embeddings\" data-toc-modified-id=\"Combining-with-embeddings-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Combining with embeddings</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#Embedding-with-only-temperature\" data-toc-modified-id=\"Embedding-with-only-temperature-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Embedding with only temperature</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/rnn.ipynb#Add-previous-forecasts-and-observations-as-features\" data-toc-modified-id=\"Add-previous-forecasts-and-observations-as-features-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Add previous forecasts and observations as features</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural networks\n",
    "\n",
    "In this notebook we will try out RNNs for our post-processing. The idea here is that there might be some extra information in looking at data from previous time steps.\n",
    "\n",
    "RNNs take quite a long time to train, so I am using a GPU here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anaconda environment: py36_keras\n",
      "Darwin 17.2.0\n",
      "Anaconda environment: py36_keras\n",
      "Darwin 17.2.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from importlib import reload\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "import keras_models; reload(keras_models)\n",
    "from keras_models import *\n",
    "import losses; reload(losses)\n",
    "from losses import crps_cost_function, crps_cost_function_seq\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, merge, Embedding, Flatten, Dropout, \\\n",
    "    SimpleRNN, LSTM, TimeDistributed, GRU, Dropout, Masking\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model, Sequential\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this if you want to limit the GPU RAM usage\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic setup\n",
    "DATA_DIR = '/Volumes/STICK/data/ppnn_data/'  # Mac\n",
    "# DATA_DIR = '/project/meteo/w2w/C7/ppnn_data/'   # LMU\n",
    "results_dir = '../results/'\n",
    "window_size = 25   # Days in rolling window\n",
    "fclt = 48   # Forecast lead time in hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Set up data\n",
    "\n",
    "This is now also done inside the `get_train_test_sets` function. `seq_len` is the number of timesteps (including the one to predict). We will start out with a moderate length of 5 days, training for 2015, predicting for 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "seq_len=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 365 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "train_dates = ['2015-01-01', '2016-01-01']\n",
    "test_dates =  ['2016-01-01', '2017-01-01']\n",
    "train_set, test_set = get_train_test_sets(DATA_DIR, train_dates, test_dates, \n",
    "                                          seq_len=seq_len, fill_value=-999.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180849, 5, 2), (180849, 5, 1))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.features.shape, train_set.targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The arrays have dimensions [sample, time step, feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## RNNs with only temperature data\n",
    "\n",
    "As a comparison. Our simple networks got a train/test loss of around 1.07/1.01.\n",
    "\n",
    "I am using a Gated Recurrent Unit (GRU) as my recurrent layer. LSTM is probably the more common one, but GRU is slightly cheaper and for our simple applications provides similar results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### RNN predicting only the last target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "hidden_nodes = 100   # Number of hidden nodes inside RNN cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(seq_len, 2, )) # time step, feature\n",
    "x = GRU(hidden_nodes)(inp)\n",
    "x = Dense(2, activation='linear')(x)\n",
    "rnn_model = Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer=Adam(0.01), loss=crps_cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 5, 2)              0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 100)               30900     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 31,102\n",
      "Trainable params: 31,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 4s - loss: 1.8537 - val_loss: 1.0207\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 3s - loss: 1.0508 - val_loss: 1.0188\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 3s - loss: 1.0394 - val_loss: 1.0122\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 3s - loss: 1.0360 - val_loss: 1.0078\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 3s - loss: 1.0333 - val_loss: 1.0066\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 3s - loss: 1.0287 - val_loss: 1.0079\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 3s - loss: 1.0280 - val_loss: 1.0193\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 3s - loss: 1.0236 - val_loss: 1.0325\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 3s - loss: 1.0190 - val_loss: 1.0185\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 3s - loss: 1.0131 - val_loss: 1.0348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c7d37e7f0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(train_set.features, train_set.targets[:,-1], epochs=10, batch_size=batch_size,\n",
    "              validation_data=(test_set.features, test_set.targets[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So we get a better train score and a worse validation score. This indicates overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Sequence RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(seq_len, 2, )) # time step, feature\n",
    "x = GRU(hidden_nodes, return_sequences=True)(inp)\n",
    "x = TimeDistributed(Dense(2, activation='linear'))(x)\n",
    "seq_rnn_model = Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5, 2)              0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 5, 100)            30900     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 5, 2)              202       \n",
      "=================================================================\n",
      "Total params: 31,102\n",
      "Trainable params: 31,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "seq_rnn_model.compile(optimizer=Adam(0.01), loss=crps_cost_function_seq, \n",
    "                      sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_and_valid(model, train_set, test_set, epochs, batch_size, verbose=0, emb=False):\n",
    "    \"\"\"Write our own function to train and validate, \n",
    "    because the keras fit function cannot handle sample weights for training\n",
    "    and validation at the same time.\n",
    "    \"\"\"\n",
    "    train_inp = [train_set.features, train_set.cont_ids] if emb else train_set.features\n",
    "    test_inp = [test_set.features, test_set.cont_ids] if emb else test_set.features\n",
    "    for i in range(epochs):\n",
    "        print('Epoch:', i+1)\n",
    "        t1 = timeit.default_timer()\n",
    "        \n",
    "        h = model.fit(train_inp, train_set.targets, epochs=1, batch_size=batch_size, \n",
    "                      sample_weight=train_set.sample_weights, verbose=verbose)\n",
    "        t2 = timeit.default_timer()\n",
    "        print('Train loss: %.4f - Valid loss: %.4f - Time: %.1fs' % (h.history['loss'][0],  \n",
    "                    model.evaluate(test_inp, test_set.targets, batch_size=10000, \n",
    "                       sample_weight=test_set.sample_weights, verbose=verbose), \n",
    "                    t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 1.0207 - Valid loss: 1.0338\n",
      "Epoch: 2\n",
      "Train loss: 1.0179 - Valid loss: 1.0420\n",
      "Epoch: 3\n",
      "Train loss: 1.0173 - Valid loss: 1.0316\n",
      "Epoch: 4\n",
      "Train loss: 1.0161 - Valid loss: 1.0381\n",
      "Epoch: 5\n",
      "Train loss: 1.0135 - Valid loss: 1.0471\n",
      "Epoch: 6\n",
      "Train loss: 1.0123 - Valid loss: 1.0401\n",
      "Epoch: 7\n",
      "Train loss: 1.0117 - Valid loss: 1.0343\n",
      "Epoch: 8\n",
      "Train loss: 1.0089 - Valid loss: 1.0547\n",
      "Epoch: 9\n",
      "Train loss: 1.0078 - Valid loss: 1.0515\n",
      "Epoch: 10\n",
      "Train loss: 1.0064 - Valid loss: 1.0479\n"
     ]
    }
   ],
   "source": [
    "train_and_valid(seq_rnn_model, train_set, test_set, 10, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Same as with the first RNN above we seem to overfit to the dataset, but maybe not as strongly. Let's now try a more complex model with a longer sequence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Longer sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 365 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "seq_len = 20\n",
    "train_dates = ['2015-01-01', '2016-01-01']\n",
    "test_dates =  ['2016-01-01', '2017-01-01']\n",
    "train_set, test_set = get_train_test_sets(DATA_DIR, train_dates, test_dates, \n",
    "                                          seq_len=seq_len, fill_value=-999.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hidden_nodes = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(seq_len, 2, )) # time step, feature\n",
    "x = GRU(hidden_nodes, return_sequences=True)(inp)\n",
    "x = TimeDistributed(Dense(2, activation='linear'))(x)\n",
    "seq_rnn_model = Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 20, 2)             0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 20, 200)           121800    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 2)             402       \n",
      "=================================================================\n",
      "Total params: 122,202\n",
      "Trainable params: 122,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "seq_rnn_model.compile(optimizer=Adam(0.01), loss=crps_cost_function_seq, \n",
    "                      sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 1.7379 - Valid loss: 1.0252\n",
      "Epoch: 2\n",
      "Train loss: 1.0267 - Valid loss: 1.0240\n",
      "Epoch: 3\n",
      "Train loss: 1.0123 - Valid loss: 1.0222\n",
      "Epoch: 4\n",
      "Train loss: 0.9968 - Valid loss: 1.0459\n",
      "Epoch: 5\n",
      "Train loss: 0.9759 - Valid loss: 1.0582\n",
      "Epoch: 6\n",
      "Train loss: 0.9524 - Valid loss: 1.0647\n",
      "Epoch: 7\n",
      "Train loss: 0.9270 - Valid loss: 1.0764\n",
      "Epoch: 8\n",
      "Train loss: 0.9082 - Valid loss: 1.0816\n",
      "Epoch: 9\n",
      "Train loss: 0.8912 - Valid loss: 1.1043\n",
      "Epoch: 10\n",
      "Train loss: 0.8779 - Valid loss: 1.0920\n"
     ]
    }
   ],
   "source": [
    "train_and_valid(seq_rnn_model, train_set, test_set, 10, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So again we are overfitting, but maybe there is something to be learned. Let's first add some regularization and then try a longer training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(seq_len, 2, )) # time step, feature\n",
    "x = GRU(hidden_nodes, return_sequences=True, recurrent_dropout=0.5)(inp)\n",
    "x = TimeDistributed(Dense(2, activation='linear'))(x)\n",
    "seq_rnn_model = Model(inputs=inp, outputs=x)\n",
    "seq_rnn_model.compile(optimizer=Adam(0.001), loss=crps_cost_function_seq, \n",
    "                      sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 1.0384 - Valid loss: 1.0048\n",
      "Epoch: 2\n",
      "Train loss: 1.0361 - Valid loss: 1.0030\n",
      "Epoch: 3\n",
      "Train loss: 1.0342 - Valid loss: 1.0019\n",
      "Epoch: 4\n",
      "Train loss: 1.0332 - Valid loss: 1.0035\n",
      "Epoch: 5\n",
      "Train loss: 1.0319 - Valid loss: 1.0027\n",
      "Epoch: 6\n",
      "Train loss: 1.0309 - Valid loss: 1.0033\n",
      "Epoch: 7\n",
      "Train loss: 1.0301 - Valid loss: 1.0073\n",
      "Epoch: 8\n",
      "Train loss: 1.0290 - Valid loss: 1.0035\n",
      "Epoch: 9\n",
      "Train loss: 1.0284 - Valid loss: 1.0086\n",
      "Epoch: 10\n",
      "Train loss: 1.0278 - Valid loss: 1.0054\n"
     ]
    }
   ],
   "source": [
    "train_and_valid(seq_rnn_model, train_set, test_set, 10, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So with drop out we get slightly better validation results, but we are still starting to overfit. I think there is a lot of parameter tuning that would be possible with the complexity of the network and so forth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Reference experiment with longer training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 2922 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "train_dates_long = ['2008-01-01', '2016-01-01']\n",
    "train_set, test_set = get_train_test_sets(DATA_DIR, train_dates_long, test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Copied from fc_network notebook\n",
    "def build_fc_model():\n",
    "    inp = Input(shape=(2,))\n",
    "    x = Dense(2, activation='linear')(inp)\n",
    "    return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fc_model = build_fc_model()\n",
    "fc_model.compile(optimizer=Adam(0.1), loss=crps_cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1456977 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "1456977/1456977 [==============================] - 6s - loss: 1.3737 - val_loss: 1.0100\n",
      "Epoch 2/10\n",
      "1456977/1456977 [==============================] - 5s - loss: 1.0626 - val_loss: 1.0109\n",
      "Epoch 3/10\n",
      "1456977/1456977 [==============================] - 5s - loss: 1.0628 - val_loss: 1.0079\n",
      "Epoch 4/10\n",
      "1456977/1456977 [==============================] - 5s - loss: 1.0630 - val_loss: 1.0126\n",
      "Epoch 5/10\n",
      "1456977/1456977 [==============================] - 5s - loss: 1.0630 - val_loss: 1.0109\n",
      "Epoch 6/10\n",
      "1456977/1456977 [==============================] - 5s - loss: 1.0630 - val_loss: 1.0074\n",
      "Epoch 7/10\n",
      "1456977/1456977 [==============================] - 5s - loss: 1.0629 - val_loss: 1.0119\n",
      "Epoch 8/10\n",
      "1456977/1456977 [==============================] - 5s - loss: 1.0630 - val_loss: 1.0130\n",
      "Epoch 9/10\n",
      "1456977/1456977 [==============================] - 5s - loss: 1.0630 - val_loss: 1.0082\n",
      "Epoch 10/10\n",
      "1456977/1456977 [==============================] - 5s - loss: 1.0630 - val_loss: 1.0167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c519fccc0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.fit(train_set.features, train_set.targets, epochs=10, batch_size=1024,\n",
    "             validation_data=[test_set.features, test_set.targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Maybe a small improvement. Now let's test our sequence model with a longer training period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Sequence model with longer training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 2922 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "seq_len = 20\n",
    "train_set, test_set = get_train_test_sets(DATA_DIR, train_dates_long, test_dates, \n",
    "                                          seq_len=seq_len, fill_value=-999.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_seq_rnn(hidden_nodes, n_features, dropout=0, lr=0.01):\n",
    "    inp = Input(shape=(seq_len, n_features, )) # time step, feature\n",
    "    x = GRU(hidden_nodes, return_sequences=True, recurrent_dropout=dropout)(inp)\n",
    "    x = TimeDistributed(Dense(2, activation='linear'))(x)\n",
    "    seq_rnn_model = Model(inputs=inp, outputs=x)\n",
    "    seq_rnn_model.compile(optimizer=Adam(lr), loss=crps_cost_function_seq, \n",
    "                          sample_weight_mode=\"temporal\")\n",
    "    return seq_rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(seq_len, 2, )) # time step, feature\n",
    "x = GRU(hidden_nodes, return_sequences=True, recurrent_dropout=0.5)(inp)\n",
    "x = TimeDistributed(Dense(2, activation='linear'))(x)\n",
    "seq_rnn_model = Model(inputs=inp, outputs=x)\n",
    "seq_rnn_model.compile(optimizer=Adam(0.001), loss=crps_cost_function_seq, \n",
    "                      sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 1.0349 - Valid loss: 0.9941\n",
      "Epoch: 2\n",
      "Train loss: 1.0333 - Valid loss: 0.9959\n"
     ]
    }
   ],
   "source": [
    "# This takes several minutes on the GPU\n",
    "# Epoch counter: 7\n",
    "train_and_valid(seq_rnn_model, train_set, test_set, 2, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get additional variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "aux_dict = OrderedDict()\n",
    "aux_dict['data_aux_geo_interpolated.nc'] = ['orog', \n",
    "                                            'station_alt', \n",
    "                                            'station_lat', \n",
    "                                            'station_lon']\n",
    "aux_dict['data_aux_pl500_interpolated_00UTC.nc'] = ['u_pl500_fc',\n",
    "                                                    'v_pl500_fc',\n",
    "                                                    'gh_pl500_fc']\n",
    "aux_dict['data_aux_pl850_interpolated_00UTC.nc'] = ['u_pl850_fc',\n",
    "                                                    'v_pl850_fc',\n",
    "                                                    'q_pl850_fc']\n",
    "aux_dict['data_aux_surface_interpolated_00UTC.nc'] = ['cape_fc',\n",
    "                                                      'sp_fc',\n",
    "                                                      'tcc_fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 365 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "# Start with just one training year\n",
    "train_set, test_set = get_train_test_sets(DATA_DIR, train_dates, test_dates, \n",
    "                                          seq_len=seq_len, fill_value=-999., aux_dict=aux_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180849, 20)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.cont_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = train_set.features.shape[-1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_rnn_model = build_seq_rnn(hidden_nodes, n_features, dropout=0.5, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch 1/1\n",
      "180849/180849 [==============================] - 18s - loss: 0.8329    \n",
      "182218/182218 [==============================] - 6s     \n",
      "Train loss: 0.8329 - Valid loss: 0.9341 - Time: 18.1s\n",
      "Epoch: 2\n",
      "Epoch 1/1\n",
      "180849/180849 [==============================] - 18s - loss: 0.8201    \n",
      "182218/182218 [==============================] - 6s     \n",
      "Train loss: 0.8201 - Valid loss: 0.9315 - Time: 18.1s\n"
     ]
    }
   ],
   "source": [
    "# Epoch counter: 8\n",
    "train_and_valid(seq_rnn_model, train_set, test_set, 2, batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 20, 24)            0         \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 20, 200)           135000    \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 20, 2)             402       \n",
      "=================================================================\n",
      "Total params: 135,402\n",
      "Trainable params: 135,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combining with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_seq_rnn_with_embeddings(seq_len, hidden_nodes, n_features, emb_size, max_id, \n",
    "                                  recurrent_dropout=0, dropout=0, lr=0.01):\n",
    "    features_inp = Input(shape=(seq_len, n_features, )) # time step, feature\n",
    "    id_in = Input(shape=(seq_len,))\n",
    "    emb = Embedding(max_id + 1, emb_size)(id_in)\n",
    "    x = GRU(hidden_nodes, return_sequences=True, recurrent_dropout=recurrent_dropout)(features_inp)\n",
    "    x = Concatenate()([x, emb])\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = TimeDistributed(Dense(2, activation='linear'))(x)\n",
    "    model = Model(inputs=[features_inp, id_in], outputs=x)\n",
    "    model.compile(optimizer=Adam(lr), loss=crps_cost_function_seq, \n",
    "                          sample_weight_mode=\"temporal\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 536)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = 5\n",
    "max_id = int(np.max([train_set.cont_ids.max(), test_set.cont_ids.max()]))\n",
    "hidden_nodes, max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_rnn = build_seq_rnn_with_embeddings(hidden_nodes, n_features, emb_size, max_id, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_24 (InputLayer)            (None, 20, 24)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_25 (InputLayer)            (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_16 (GRU)                     (None, 20, 200)       135000      input_24[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)          (None, 20, 5)         2685        input_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 20, 205)       0           gru_16[0][0]                     \n",
      "                                                                   embedding_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 20, 205)       0           concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistrib (None, 20, 2)         412         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 138,097\n",
      "Trainable params: 138,097\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 0.9147 - Valid loss: 0.8970 - Time: 19.6s\n",
      "Epoch: 2\n",
      "Train loss: 0.9016 - Valid loss: 0.8984 - Time: 19.7s\n",
      "Epoch: 3\n",
      "Train loss: 0.8923 - Valid loss: 0.9004 - Time: 19.6s\n",
      "Epoch: 4\n",
      "Train loss: 0.8822 - Valid loss: 0.9023 - Time: 19.6s\n",
      "Epoch: 5\n",
      "Train loss: 0.8737 - Valid loss: 0.8983 - Time: 19.6s\n"
     ]
    }
   ],
   "source": [
    "train_and_valid(emb_rnn, train_set, test_set, 5, batch_size, emb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Embedding with only temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 365 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = get_train_test_sets(DATA_DIR, train_dates, test_dates, \n",
    "                                          seq_len=2, fill_value=-999.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_rnn = build_seq_rnn_with_embeddings(2, 10, 2, emb_size, max_id, recurrent_dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_36 (InputLayer)            (None, 2, 2)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_37 (InputLayer)            (None, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_22 (GRU)                     (None, 2, 10)         390         input_36[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)         (None, 2, 5)          2685        input_37[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)     (None, 2, 15)         0           gru_22[0][0]                     \n",
      "                                                                   embedding_14[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 2, 15)         0           concatenate_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistrib (None, 2, 2)          32          dropout_7[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3,107\n",
      "Trainable params: 3,107\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 0.9538 - Valid loss: 0.9194 - Time: 1.2s\n",
      "Epoch: 2\n",
      "Train loss: 0.9534 - Valid loss: 0.9233 - Time: 1.1s\n",
      "Epoch: 3\n",
      "Train loss: 0.9541 - Valid loss: 0.9263 - Time: 1.1s\n",
      "Epoch: 4\n",
      "Train loss: 0.9538 - Valid loss: 0.9229 - Time: 1.2s\n",
      "Epoch: 5\n",
      "Train loss: 0.9536 - Valid loss: 0.9233 - Time: 1.1s\n"
     ]
    }
   ],
   "source": [
    "train_and_valid(emb_rnn, train_set, test_set, 5, batch_size, emb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 2922 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "train_dates_long = ['2008-01-01', '2016-01-01']\n",
    "train_set_long, test_set = get_train_test_sets(DATA_DIR, train_dates_long, test_dates, \n",
    "                                          seq_len=seq_len, fill_value=-999.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_rnn = build_seq_rnn_with_embeddings(seq_len, 30, 2, emb_size, max_id, recurrent_dropout=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 1.2161 - Valid loss: 0.9024 - Time: 40.9s\n",
      "Epoch: 2\n",
      "Train loss: 0.9281 - Valid loss: 0.8962 - Time: 38.3s\n",
      "Epoch: 3\n",
      "Train loss: 0.9255 - Valid loss: 0.8949 - Time: 38.3s\n",
      "Epoch: 4\n",
      "Train loss: 0.9239 - Valid loss: 0.8965 - Time: 38.3s\n",
      "Epoch: 5\n",
      "Train loss: 0.9227 - Valid loss: 0.8954 - Time: 38.3s\n",
      "Epoch: 6\n",
      "Train loss: 0.9216 - Valid loss: 0.9010 - Time: 38.3s\n",
      "Epoch: 7\n",
      "Train loss: 0.9210 - Valid loss: 0.9060 - Time: 38.3s\n",
      "Epoch: 8\n",
      "Train loss: 0.9205 - Valid loss: 0.8914 - Time: 38.2s\n",
      "Epoch: 9\n",
      "Train loss: 0.9198 - Valid loss: 0.8937 - Time: 38.3s\n",
      "Epoch: 10\n",
      "Train loss: 0.9193 - Valid loss: 0.8931 - Time: 38.2s\n",
      "Epoch: 11\n",
      "Train loss: 0.9191 - Valid loss: 0.8955 - Time: 38.2s\n",
      "Epoch: 12\n",
      "Train loss: 0.9188 - Valid loss: 0.9047 - Time: 38.2s\n",
      "Epoch: 13\n",
      "Train loss: 0.9186 - Valid loss: 0.8932 - Time: 38.2s\n",
      "Epoch: 14\n",
      "Train loss: 0.9184 - Valid loss: 0.8945 - Time: 38.2s\n",
      "Epoch: 15\n",
      "Train loss: 0.9183 - Valid loss: 0.8993 - Time: 38.2s\n"
     ]
    }
   ],
   "source": [
    "train_and_valid(emb_rnn, train_set_long, test_set, 15, batch_size, emb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Add previous forecasts and observations as features\n",
    "\n",
    "Let's try a very simple form of memory. Simply adding the forecast, observation and error at the current time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 365 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "train_dates = ['2015-01-01', '2016-01-01']\n",
    "test_dates =  ['2016-01-01', '2017-01-01']\n",
    "train_set, test_set = get_train_test_sets(DATA_DIR, train_dates, test_dates,\n",
    "                                          add_current_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t2m_fc_mean',\n",
       " 't2m_fc_std',\n",
       " 'curr_t2m_fc_mean',\n",
       " 'curr_t2m_fc_obs',\n",
       " 'curr_err']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195929, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.16025579e-01,   5.29616654e-01,  -9.77649316e-02,\n",
       "         -5.11945412e-02,   7.73962587e-02],\n",
       "       [ -2.98225224e-01,   2.79068202e-01,  -9.18984637e-02,\n",
       "         -8.19112659e-02,   8.43664748e-04],\n",
       "       [ -4.24173504e-01,   9.02967393e-01,  -2.06207782e-01,\n",
       "         -9.55631435e-02,   1.89672261e-01],\n",
       "       ..., \n",
       "       [ -2.37503141e-01,   3.89254838e-01,  -1.53460518e-01,\n",
       "         -2.42320821e-01,  -2.23194495e-01],\n",
       "       [ -1.56708300e-01,   2.30311200e-01,  -2.50977844e-01,\n",
       "         -3.58361781e-01,  -2.84274936e-01],\n",
       "       [ -3.31122875e-01,   8.02613497e-01,  -4.61168319e-01,\n",
       "         -3.24232101e-01,   1.88998073e-01]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.features[10000:11000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = build_fc_model(5, 2, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 195929 samples, validate on 196468 samples\n",
      "Epoch 1/10\n",
      "195929/195929 [==============================] - 1s - loss: 2.2785 - val_loss: 1.3932\n",
      "Epoch 2/10\n",
      "195929/195929 [==============================] - 1s - loss: 1.2732 - val_loss: 1.1072\n",
      "Epoch 3/10\n",
      "195929/195929 [==============================] - 1s - loss: 1.0611 - val_loss: 0.9511\n",
      "Epoch 4/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.9821 - val_loss: 0.9131\n",
      "Epoch 5/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.9691 - val_loss: 0.9087\n",
      "Epoch 6/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.9681 - val_loss: 0.9089\n",
      "Epoch 7/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.9681 - val_loss: 0.9077\n",
      "Epoch 8/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.9680 - val_loss: 0.9086\n",
      "Epoch 9/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.9681 - val_loss: 0.9094\n",
      "Epoch 10/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.9684 - val_loss: 0.9070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1252dcda0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: I am running this cell several times \n",
    "fc_model.fit(train_set.features, train_set.targets, epochs=10, batch_size=1024,\n",
    "             validation_data=[test_set.features, test_set.targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erm ok wow, that is pretty incredible. But wait maybe this is very similar to the embedding information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6ed4c7f7ac83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0memb_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmax_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcont_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcont_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmax_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "emb_size = 3\n",
    "max_id = int(np.max([train_set.cont_ids.max(), test_set.cont_ids.max()]))\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model = build_emb_model(5, 2, [], emb_size, max_id, compile=True,\n",
    "                            lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 195929 samples, validate on 196468 samples\n",
      "Epoch 1/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.8947 - val_loss: 0.8393\n",
      "Epoch 2/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.8947 - val_loss: 0.8402\n",
      "Epoch 3/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.8946 - val_loss: 0.8397\n",
      "Epoch 4/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.8946 - val_loss: 0.8405\n",
      "Epoch 5/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.8946 - val_loss: 0.8414\n",
      "Epoch 6/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.8946 - val_loss: 0.8396\n",
      "Epoch 7/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.8946 - val_loss: 0.8393\n",
      "Epoch 8/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.8945 - val_loss: 0.8394\n",
      "Epoch 9/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.8945 - val_loss: 0.8400\n",
      "Epoch 10/10\n",
      "195929/195929 [==============================] - 1s - loss: 0.8946 - val_loss: 0.8391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110793f98>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, \n",
    "              epochs=10, batch_size=1024, \n",
    "              validation_data=[[test_set.features, test_set.cont_ids], test_set.targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, I need to check whether I am cheating, but for now let's try to build the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "more_aux_dict = OrderedDict()\n",
    "more_aux_dict['data_aux_geo_interpolated.nc'] = ['orog', \n",
    "                                            'station_alt', \n",
    "                                            'station_lat', \n",
    "                                            'station_lon']\n",
    "more_aux_dict['data_aux_pl500_interpolated_00UTC.nc'] = ['u_pl500_fc',\n",
    "                                                    'v_pl500_fc',\n",
    "                                                    'gh_pl500_fc']\n",
    "more_aux_dict['data_aux_pl850_interpolated_00UTC.nc'] = ['u_pl850_fc',\n",
    "                                                    'v_pl850_fc',\n",
    "                                                    'q_pl850_fc']\n",
    "more_aux_dict['data_aux_surface_interpolated_00UTC.nc'] = ['cape_fc',\n",
    "                                                      'sp_fc',\n",
    "                                                      'tcc_fc']\n",
    "more_aux_dict['data_aux_surface_more_interpolated_part1_00UTC.nc']  = [\n",
    "    'sshf_fc', 'slhf_fc', 'u10_fc','v10_fc'\n",
    "]\n",
    "more_aux_dict['data_aux_surface_more_interpolated_part2_00UTC.nc']  = [\n",
    "    'ssr_fc', 'str_fc', 'd2m_fc','sm_fc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 365 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "train_dates = ['2015-01-01', '2016-01-01']\n",
    "test_dates =  ['2016-01-01', '2017-01-01']\n",
    "more_train_set, more_test_set = get_train_test_sets(DATA_DIR, train_dates, test_dates,\n",
    "                                         aux_dict=more_aux_dict, add_current_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = 3\n",
    "max_id = int(np.max([more_train_set.cont_ids.max(), more_test_set.cont_ids.max()]))\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model = build_emb_model(more_train_set.features.shape[1], 2, [50], 3, max_id, \n",
    "                            compile=True, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"458pt\" viewBox=\"0.00 0.00 564.07 458.00\" width=\"564pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 454)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-454 560.069,-454 560.069,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4519169216 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4519169216</title>\n",
       "<polygon fill=\"none\" points=\"24.8896,-405.5 24.8896,-449.5 278.569,-449.5 278.569,-405.5 24.8896,-405.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.0708\" y=\"-423.3\">input_4: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"153.252,-405.5 153.252,-449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181.086\" y=\"-434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"153.252,-427.5 208.921,-427.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181.086\" y=\"-412.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"208.921,-405.5 208.921,-449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.745\" y=\"-434.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"208.921,-427.5 278.569,-427.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.745\" y=\"-412.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 4519168824 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4519168824</title>\n",
       "<polygon fill=\"none\" points=\"0,-324.5 0,-368.5 303.459,-368.5 303.459,-324.5 0,-324.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82.0708\" y=\"-342.3\">embedding_2: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"164.142,-324.5 164.142,-368.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191.976\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"164.142,-346.5 219.811,-346.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191.976\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"219.811,-324.5 219.811,-368.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261.635\" y=\"-353.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"219.811,-346.5 303.459,-346.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261.635\" y=\"-331.3\">(None, 1, 3)</text>\n",
       "</g>\n",
       "<!-- 4519169216&#45;&gt;4519168824 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4519169216-&gt;4519168824</title>\n",
       "<path d=\"M151.729,-405.329C151.729,-397.183 151.729,-387.699 151.729,-378.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"155.23,-378.729 151.729,-368.729 148.23,-378.729 155.23,-378.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4519121528 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4519121528</title>\n",
       "<polygon fill=\"none\" points=\"26.438,-243.5 26.438,-287.5 277.021,-287.5 277.021,-243.5 26.438,-243.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82.0708\" y=\"-261.3\">flatten_2: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"137.704,-243.5 137.704,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165.538\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"137.704,-265.5 193.373,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165.538\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"193.373,-243.5 193.373,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.197\" y=\"-272.3\">(None, 1, 3)</text>\n",
       "<polyline fill=\"none\" points=\"193.373,-265.5 277.021,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.197\" y=\"-250.3\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 4519168824&#45;&gt;4519121528 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4519168824-&gt;4519121528</title>\n",
       "<path d=\"M151.729,-324.329C151.729,-316.183 151.729,-306.699 151.729,-297.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"155.23,-297.729 151.729,-287.729 148.23,-297.729 155.23,-297.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4519169888 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4519169888</title>\n",
       "<polygon fill=\"none\" points=\"295.39,-243.5 295.39,-287.5 556.069,-287.5 556.069,-243.5 295.39,-243.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359.571\" y=\"-261.3\">input_3: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"423.752,-243.5 423.752,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451.586\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"423.752,-265.5 479.421,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451.586\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"479.421,-243.5 479.421,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517.745\" y=\"-272.3\">(None, 43)</text>\n",
       "<polyline fill=\"none\" points=\"479.421,-265.5 556.069,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517.745\" y=\"-250.3\">(None, 43)</text>\n",
       "</g>\n",
       "<!-- 4519146776 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4519146776</title>\n",
       "<polygon fill=\"none\" points=\"101.265,-162.5 101.265,-206.5 476.194,-206.5 476.194,-162.5 101.265,-162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187.584\" y=\"-180.3\">concatenate_2: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"273.904,-162.5 273.904,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301.738\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"273.904,-184.5 329.573,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301.738\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"329.573,-162.5 329.573,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402.883\" y=\"-191.3\">[(None, 43), (None, 3)]</text>\n",
       "<polyline fill=\"none\" points=\"329.573,-184.5 476.194,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402.397\" y=\"-169.3\">(None, 46)</text>\n",
       "</g>\n",
       "<!-- 4519169888&#45;&gt;4519146776 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4519169888-&gt;4519146776</title>\n",
       "<path d=\"M389.016,-243.329C372.277,-233.677 352.285,-222.149 334.571,-211.934\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"335.956,-208.692 325.544,-206.729 332.459,-214.756 335.956,-208.692\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4519121528&#45;&gt;4519146776 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>4519121528-&gt;4519146776</title>\n",
       "<path d=\"M188.443,-243.329C205.182,-233.677 225.174,-222.149 242.888,-211.934\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"245,-214.756 251.915,-206.729 241.503,-208.692 245,-214.756\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4519308480 -->\n",
       "<g class=\"node\" id=\"node6\"><title>4519308480</title>\n",
       "<polygon fill=\"none\" points=\"170.445,-81.5 170.445,-125.5 407.014,-125.5 407.014,-81.5 170.445,-81.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"222.571\" y=\"-99.3\">dense_3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"274.697,-81.5 274.697,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302.531\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"274.697,-103.5 330.366,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302.531\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"330.366,-81.5 330.366,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.69\" y=\"-110.3\">(None, 46)</text>\n",
       "<polyline fill=\"none\" points=\"330.366,-103.5 407.014,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.69\" y=\"-88.3\">(None, 50)</text>\n",
       "</g>\n",
       "<!-- 4519146776&#45;&gt;4519308480 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>4519146776-&gt;4519308480</title>\n",
       "<path d=\"M288.729,-162.329C288.729,-154.183 288.729,-144.699 288.729,-135.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"292.23,-135.729 288.729,-125.729 285.23,-135.729 292.23,-135.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4519307752 -->\n",
       "<g class=\"node\" id=\"node7\"><title>4519307752</title>\n",
       "<polygon fill=\"none\" points=\"170.445,-0.5 170.445,-44.5 407.014,-44.5 407.014,-0.5 170.445,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"222.571\" y=\"-18.3\">dense_4: Dense</text>\n",
       "<polyline fill=\"none\" points=\"274.697,-0.5 274.697,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302.531\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"274.697,-22.5 330.366,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302.531\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"330.366,-0.5 330.366,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.69\" y=\"-29.3\">(None, 50)</text>\n",
       "<polyline fill=\"none\" points=\"330.366,-22.5 407.014,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368.69\" y=\"-7.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 4519308480&#45;&gt;4519307752 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>4519308480-&gt;4519307752</title>\n",
       "<path d=\"M288.729,-81.3294C288.729,-73.1826 288.729,-63.6991 288.729,-54.7971\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"292.23,-54.729 288.729,-44.729 285.23,-54.729 292.23,-54.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG, \n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(emb_model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "195929/195929 [==============================] - 1s - loss: 2.9915     \n",
      "Epoch 2/30\n",
      "195929/195929 [==============================] - 0s - loss: 1.4867     \n",
      "Epoch 3/30\n",
      "195929/195929 [==============================] - 0s - loss: 1.1565     \n",
      "Epoch 4/30\n",
      "195929/195929 [==============================] - 0s - loss: 1.0191     \n",
      "Epoch 5/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.9549     \n",
      "Epoch 6/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.9258     \n",
      "Epoch 7/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.9055     \n",
      "Epoch 8/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8949     \n",
      "Epoch 9/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8780     \n",
      "Epoch 10/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8752     \n",
      "Epoch 11/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8520     \n",
      "Epoch 12/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8502     \n",
      "Epoch 13/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8371     \n",
      "Epoch 14/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8437     \n",
      "Epoch 15/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8349     \n",
      "Epoch 16/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8347     \n",
      "Epoch 17/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8179     \n",
      "Epoch 18/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8196     \n",
      "Epoch 19/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8174     \n",
      "Epoch 20/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8100     \n",
      "Epoch 21/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8153     \n",
      "Epoch 22/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8129     \n",
      "Epoch 23/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8037     \n",
      "Epoch 24/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.7969     \n",
      "Epoch 25/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8030     \n",
      "Epoch 26/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8060     \n",
      "Epoch 27/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8078     \n",
      "Epoch 28/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8003     \n",
      "Epoch 29/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.8022     \n",
      "Epoch 30/30\n",
      "195929/195929 [==============================] - 0s - loss: 0.7991     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c6317f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit([more_train_set.features, more_train_set.cont_ids], more_train_set.targets, epochs=30, \n",
    "              batch_size=4096, validation_split=0.0)\n",
    "              #callbacks=[EarlyStopping(monitor='val_loss', \n",
    "              #                         min_delta=0,\n",
    "              #                         patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000/196468 [========================>.....] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8035658740438123"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate([more_test_set.features, more_test_set.cont_ids], more_test_set.targets, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 1, 3)          1611        input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 43)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 3)             0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 46)            0           input_5[0][0]                    \n",
      "                                                                   flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 50)            2350        concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 2)             102         dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 4,063\n",
      "Trainable params: 4,063\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "long_train_dates = ['2008-01-01', '2016-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 2922 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "long_more_train_set, more_test_set = get_train_test_sets(DATA_DIR, long_train_dates, test_dates,\n",
    "                                                         aux_dict=more_aux_dict,\n",
    "                                                        add_current_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model = build_emb_model(long_more_train_set.features.shape[1], 2, [50], 3, max_id, \n",
    "                            compile=True, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1255230 samples, validate on 313808 samples\n",
      "Epoch 1/50\n",
      "1255230/1255230 [==============================] - 5s - loss: 1.3354 - val_loss: 0.8262\n",
      "Epoch 2/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.8367 - val_loss: 0.8129\n",
      "Epoch 3/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.8255 - val_loss: 0.8046\n",
      "Epoch 4/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.8171 - val_loss: 0.8009\n",
      "Epoch 5/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.8090 - val_loss: 0.7965\n",
      "Epoch 6/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.8048 - val_loss: 0.7951\n",
      "Epoch 7/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.8020 - val_loss: 0.7882\n",
      "Epoch 8/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.8000 - val_loss: 0.7909\n",
      "Epoch 9/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.7973 - val_loss: 0.7899\n",
      "Epoch 10/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.7941 - val_loss: 0.7871\n",
      "Epoch 11/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.7945 - val_loss: 0.7897\n",
      "Epoch 12/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.7905 - val_loss: 0.7857\n",
      "Epoch 13/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.7905 - val_loss: 0.7850\n",
      "Epoch 14/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.7891 - val_loss: 0.7879\n",
      "Epoch 15/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.7871 - val_loss: 0.7824\n",
      "Epoch 16/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.7864 - val_loss: 0.7932\n",
      "Epoch 17/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.7851 - val_loss: 0.8079\n",
      "Epoch 18/50\n",
      "1255230/1255230 [==============================] - 4s - loss: 0.7846 - val_loss: 0.7901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f930b70>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit([long_more_train_set.features, long_more_train_set.cont_ids], long_more_train_set.targets, epochs=50, \n",
    "              batch_size=4096, validation_split=0.2,\n",
    "              callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                       min_delta=0,\n",
    "                                       patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000/196468 [========================>.....] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78701121256110074"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate([more_test_set.features, more_test_set.cont_ids], test_set.targets, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
