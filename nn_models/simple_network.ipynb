{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network to minimize CRPS\n",
    "\n",
    "**Steps (to be updated)**\n",
    "1. Set up network structure (first here, then probably in separate module)\n",
    "2. Try feeding some data to the model and sanity-check the output\n",
    "3. Run the network on the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EMOS analog is a simple network like this:\n",
    "\n",
    "![title](EMOS_network.png)\n",
    "\n",
    "I will try to build a basic model like this in Keras, since this is the simplest library. There are two complications: \n",
    "\n",
    "1. This is not a fully connected layer, so we have to find a workaround, but I think something like this should work: https://github.com/fchollet/keras/issues/3919\n",
    "2. We need to write a custom CRPS loss function. We should probably use theano as a backend to make it compatible with Kai P.'s code. Example for keras loss functions: https://keras.io/losses/ or here: https://github.com/fchollet/keras/issues/369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why do we have to write that function extra. They are hooks for interacting with the graph... aha.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok here we go... http://www.marekrei.com/blog/theano-tutorial/\n",
    "\n",
    "# Let's create variables for the input\n",
    "meanx = theano.tensor.fscalar('meanx')   # This is for 32 bit floats\n",
    "\n",
    "# Now the weights and biases a and b\n",
    "a = theano.shared(np.asarray(0.5), 'a')  # The explisit names help with debugging\n",
    "b = theano.shared(np.asarray(2.), 'b')  # Make sure this is a float!!!\n",
    "\n",
    "# Let's define mu, this set's up the graph\n",
    "mu = meanx * b + a\n",
    "\n",
    "# And a function that takes input and returns output\n",
    "# What happens without the brackets? Error: Input variables of a Theano function should be contained in a list, even when there is a single input.\n",
    "f = theano.function([meanx], mu)\n",
    "\n",
    "# Let's evaluate the output\n",
    "# Can I leave out the brackets here?\n",
    "# Nope: Wrong number of dimensions: expected 1, got 0 with shape ().\n",
    "out = f(1)\n",
    "\n",
    "# So the input to f can either be a 1D numpy array with float32 or a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.5,  4.5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let' now actaully train.\n",
    "\n",
    "# Does my graph still exist?\n",
    "f(np.asarray([1, 2], dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes. \n",
    "\n",
    "# Define a target\n",
    "target = theano.tensor.fscalar('target')\n",
    "\n",
    "# Define a loss/cost function, simple squared distance\n",
    "cost = theano.tensor.sqr(target - mu)\n",
    "# This needs to be a scalar, so we need to define the input x as a scalar\n",
    "# For now, I guess later we can define both x and target as vectors.\n",
    "\n",
    "# Compute partial derivatives of cost function with respect to weights\n",
    "gradients = theano.tensor.grad(cost, [a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create updated variables\n",
    "a_updated = a - (0.01 * gradients[0])\n",
    "b_updated = b - (0.01 * gradients[1])\n",
    "\n",
    "# And write a function that replaces the pld variable with the updated value\n",
    "updates = [(a, a_updated), (b, b_updated)]\n",
    "\n",
    "# Now lets define a function again to do something\n",
    "f = theano.function([meanx, target], mu, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5527.95796295493\n",
      "5.587731639540578\n",
      "2.0023293369952597\n",
      "2.000001512323491\n",
      "2.000000000981877\n",
      "2.0000000000006377\n",
      "2.0000000000000004\n",
      "2.0\n",
      "2.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "# Now let's train\n",
    "for i in range(100):\n",
    "    out = f(5, 2)   # Start with input 5 and target 2\n",
    "    if i%10 == 0: print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it works, somewhat, but I feel like this is very clumsy and I don't actually want to write the code this way. But before looking at better code, I should maybe try to include the variance and CRPS cost function.\n",
    "\n",
    "But wait, why was the initial guess so freaking far off... Something might be wrong here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy the mean part from above and add the std\n",
    "\n",
    "# Let's create variables for the input\n",
    "meanx = theano.tensor.fscalar('meanx')   # This is for 32 bit floats\n",
    "stdx = theano.tensor.fscalar('stdx')\n",
    "\n",
    "# Now the weights and biases a and b\n",
    "a = theano.shared(np.asarray(0.5), 'a')  # The explisit names help with debugging\n",
    "b = theano.shared(np.asarray(2.), 'b')  # Make sure this is a float!!!\n",
    "c = theano.shared(np.asarray(0.5), 'c')\n",
    "d = theano.shared(np.asarray(2.), 'd') \n",
    "\n",
    "# Let's define mu and also sigma\n",
    "mu = meanx * b + a\n",
    "sigma = stdx * d + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "# Now the target which is still a scalar\n",
    "target = theano.tensor.fscalar('target')\n",
    "\n",
    "# And here comes the cost function\n",
    "# First a little helper variable to keep the equation short\n",
    "\n",
    "# Will this simple fix be enough to avoid the negative std problem\n",
    "var = T.sqr(sigma)\n",
    "\n",
    "loc = (target - mu) / T.sqrt(var)\n",
    "\n",
    "# This is now copied from Kai P.'s code\n",
    "phi = 1.0 / np.sqrt(2.0 * np.pi) * T.exp(-T.square(loc) / 2.0)\n",
    "Phi = 0.5 * (1.0 + T.erf(loc / np.sqrt(2.0)))\n",
    "\n",
    "crps =  T.sqrt(var) * (loc * (2. * Phi - 1.) + 2 * phi - 1. / np.sqrt(np.pi))\n",
    "\n",
    "# Now compute the gradients\n",
    "gradients = theano.tensor.grad(crps, [a, b, c, d])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's not define the updates\n",
    "lr = 0.01   # Learning rate\n",
    "\n",
    "a_updated = a - (lr * gradients[0])\n",
    "b_updated = b - (lr * gradients[1])\n",
    "c_updated = c - (lr * gradients[2])\n",
    "d_updated = d - (lr * gradients[3])\n",
    "\n",
    "updates = [(a, a_updated), (b, b_updated), (c, c_updated), (d, d_updated)]\n",
    "\n",
    "# Ok, so what does the function do:\n",
    "# The first argument, the list defines the input, \n",
    "# the second argument defines the output, can that be more than one?\n",
    "f = theano.function([meanx, stdx, target], [mu, sigma, crps], \n",
    "                    updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(6.5), array(10.5), array(3.2116223906950925)]\n",
      "[array(6.172896841328296), array(10.069281985719517), array(3.0333349789339605)]\n",
      "[array(5.856064480234552), array(9.627477198409583), array(2.8579359052154905)]\n",
      "[array(5.549384423566165), array(9.175080822190472), array(2.6852198566143)]\n",
      "[array(5.252767827338031), array(8.712543922329491), array(2.51500267424618)]\n",
      "[array(4.966156339250551), array(8.240277144289273), array(2.347118863001946)]\n",
      "[array(4.689523638032825), array(7.758653774689849), array(2.1814194874355133)]\n",
      "[array(4.422877827258022), array(7.268012205597393), array(2.0177703969119394)]\n",
      "[array(4.166264920204845), array(6.768657816241148), array(1.8560507365893308)]\n",
      "[array(3.919773772063541), array(6.260864253742679), array(1.6961517129811856)]\n"
     ]
    }
   ],
   "source": [
    "# Now let's do some training\n",
    "for i in range(100):\n",
    "    out = f(3, 5, 2)   # Start with input: [meanx = 3, stdx = 5, target = 2]\n",
    "    if i%10 == 0: print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(3.6835430045169386), array(5.744874051278793), array(1.5379755949408345)]\n",
      "[array(2.0110420472174706), array(0.1576020372779714), array(0.037139314934789745)]\n",
      "[array(1.9921016365325739), array(0.0549723980200141), array(0.013298726433425246)]\n",
      "[array(2.0054474051467346), array(-0.013570682845248927), array(0.004032216969526256)]\n",
      "[array(2.0180540055771665), array(-0.10893616183902224), array(0.026648781552628186)]\n",
      "[array(2.0964848350399143), array(0.147454903282231), array(0.0587844456704483)]\n",
      "[array(1.986253381720927), array(-0.0015220247658093433), array(0.012887907760301742)]\n",
      "[array(1.9559260455422292), array(0.12170837275047497), array(0.03474123110034233)]\n",
      "[array(2.0058490039752845), array(-0.046442732848182636), array(0.011146916184997418)]\n",
      "[array(2.0493908057584203), array(-0.1084959531987393), array(0.03417312722588535)]\n"
     ]
    }
   ],
   "source": [
    "# Yes, let's do some more training\n",
    "for i in range(1000):\n",
    "    out = f(3, 5, 2)   # Start with input: [meanx = 3, stdx = 5, target = 2]\n",
    "    if i%100 == 0: print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok wow what happened here, it got to almost perfect, but then skyrocketed off somewhere... How can the crps be negative? I get negative standard deviations.... This means I have to actually put the square in there somewhere. So let's actually use the variance instead! This looks good. Thanks Kai!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
